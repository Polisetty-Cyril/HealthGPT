{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================== CELL 1: DEPENDENCIES ==========================\nimport subprocess\nimport sys\n\nprint('ðŸ”§ Installing dependencies...')\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"pyarrow\"], capture_output=True, check=False)\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyarrow==15.0.2\", \"keybert\", \"rank-bm25\", \"faiss-cpu\", \"sacremoses\"], check=True)\nprint('âœ… Dependencies installed. RESTART kernel and run Cell 2.')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== CELL 2: IMPORTS & SETUP =====================\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport re\nimport json\nimport time\nimport pickle\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Tuple\n\nimport numpy as np\nimport torch\nimport faiss\nfrom datasets import load_dataset\nfrom sentence_transformers import SentenceTransformer\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom rank_bm25 import BM25Okapi\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"ðŸ”§ Using device: {device}\")\n\n# ============================================================================\n# CONFIGURATION FOR MENTAL HEALTH DOMAIN\n# ============================================================================\n\n@dataclass\nclass DomainConfig:\n    name: str = \"mental_health\"\n    dataset_name: str = \"Amod/mental_health_counseling_conversations\"\n    dataset_split: str = \"train\"\n    chunk_window: int = 3\n    chunk_stride: int = 1\n    embed_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n\nconfig = DomainConfig()\n\nprint(f\"ðŸ“‹ Building index for: {config.name}\")\nprint(f\"ðŸ“¦ Dataset: {config.dataset_name}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:17:56.200946Z","iopub.execute_input":"2025-11-01T18:17:56.201282Z","iopub.status.idle":"2025-11-01T18:18:26.705550Z","shell.execute_reply.started":"2025-11-01T18:17:56.201260Z","shell.execute_reply":"2025-11-01T18:18:26.704700Z"}},"outputs":[{"name":"stderr","text":"2025-11-01 18:18:11.891146: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762021092.097509     107 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762021092.149730     107 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ðŸ”§ Using device: cuda\nðŸ“‹ Building index for: mental_health\nðŸ“¦ Dataset: Amod/mental_health_counseling_conversations\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ===================== CELL 3: DATASET LOADING =====================\n\ndef extract_qa_pairs(dataset) -> list:\n    \"\"\"Extract Q&A pairs from mental health dataset.\"\"\"\n    qa_data = []\n    \n    for idx, row in enumerate(dataset):\n        try:\n            # Mental health dataset structure\n            if 'Context' in row and 'Response' in row:\n                qa_data.append({\n                    \"question\": str(row['Context']).strip(),\n                    \"answer\": str(row['Response']).strip(),\n                    \"source_id\": idx\n                })\n            # Alternative structure\n            elif 'question' in row and 'answer' in row:\n                qa_data.append({\n                    \"question\": str(row['question']).strip(),\n                    \"answer\": str(row['answer']).strip(),\n                    \"source_id\": idx\n                })\n            # Conversation format\n            elif 'conversations' in row:\n                conversations = row['conversations']\n                if isinstance(conversations, list) and len(conversations) >= 2:\n                    question = conversations[0].get('value', '') if isinstance(conversations[0], dict) else str(conversations[0])\n                    answer = conversations[1].get('value', '') if isinstance(conversations[1], dict) else str(conversations[1])\n                    if question and answer:\n                        qa_data.append({\n                            \"question\": question.strip(),\n                            \"answer\": answer.strip(),\n                            \"source_id\": idx\n                        })\n        except Exception as e:\n            if idx < 3:\n                print(f\"âš ï¸ Row {idx} skipped: {e}\")\n            continue\n    \n    return qa_data\n\n# Load dataset\nprint(f\"ðŸ“¥ Loading {config.dataset_name}...\")\ndataset = load_dataset(config.dataset_name, split=config.dataset_split)\nprint(f\"âœ… Loaded {len(dataset)} rows\")\n\n# Extract Q&A pairs\nqa_data = extract_qa_pairs(dataset)\nprint(f\"âœ… Extracted {len(qa_data)} Q&A pairs\")\n\nif len(qa_data) < 100:\n    print(f\"âš ï¸ WARNING: Only {len(qa_data)} pairs extracted!\")\n    print(f\"Sample row structure: {dataset[0]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:28:05.297957Z","iopub.execute_input":"2025-11-01T18:28:05.298842Z","iopub.status.idle":"2025-11-01T18:28:06.958406Z","shell.execute_reply.started":"2025-11-01T18:28:05.298815Z","shell.execute_reply":"2025-11-01T18:28:06.957348Z"}},"outputs":[{"name":"stdout","text":"ðŸ“¥ Loading Amod/mental_health_counseling_conversations...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62fa60ff6c464767bc03601a0e73cbf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"combined_dataset.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35b76a81b2804f03a0dab29453d6bb69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3512 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30567dd0d6074c44a31ca1ee9141aa72"}},"metadata":{}},{"name":"stdout","text":"âœ… Loaded 3512 rows\nâœ… Extracted 3512 Q&A pairs\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ===================== CELL 4: TEXT CHUNKING =====================\n\ndef create_chunks(data: List[Dict], window: int = 3, stride: int = 1) -> List[Dict]:\n    \"\"\"Create sentence-level chunks from answers.\"\"\"\n    chunks = []\n    \n    for item in data:\n        text = item.get(\"answer\", \"\")\n        if not text or len(text) < 50:\n            continue\n        \n        sentences = sent_tokenize(text)\n        if not sentences:\n            continue\n        \n        # If answer is short, keep as one chunk\n        if len(sentences) <= window:\n            chunks.append({\n                \"chunk\": \" \".join(sentences),\n                \"source_idx\": item.get(\"source_id\", -1),\n                \"chunk_id\": len(chunks)\n            })\n            continue\n        \n        # Create overlapping chunks\n        for i in range(0, max(1, len(sentences) - window + 1), stride):\n            chunks.append({\n                \"chunk\": \" \".join(sentences[i:i + window]),\n                \"source_idx\": item.get(\"source_id\", -1),\n                \"chunk_id\": len(chunks)\n            })\n    \n    return chunks\n\n# Create chunks\nprint(f\"ðŸ”ª Creating chunks (window={config.chunk_window}, stride={config.chunk_stride})...\")\nchunks = create_chunks(qa_data, window=config.chunk_window, stride=config.chunk_stride)\nprint(f\"âœ… Created {len(chunks)} chunks\")\n\n# Sample chunks\nprint(\"\\nðŸ“ Sample chunks:\")\nfor i, chunk in enumerate(chunks[:3]):\n    print(f\"{i+1}. {chunk['chunk'][:150]}...\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:28:06.960065Z","iopub.execute_input":"2025-11-01T18:28:06.960353Z","iopub.status.idle":"2025-11-01T18:28:07.543777Z","shell.execute_reply.started":"2025-11-01T18:28:06.960331Z","shell.execute_reply":"2025-11-01T18:28:07.542712Z"}},"outputs":[{"name":"stdout","text":"ðŸ”ª Creating chunks (window=3, stride=1)...\nâœ… Created 22565 chunks\n\nðŸ“ Sample chunks:\n1. If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is ...\n2. Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so ...\n3. Hello, and thank you for your question and seeking advice on this. Feelings of worthlessness is unfortunately common. In fact, most people, if not all...\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ===================== CELL 5: BUILD FAISS INDEX =====================\n\n# Load embedder\nprint(f\"ðŸ“¦ Loading embedder: {config.embed_model}\")\nembedder = SentenceTransformer(config.embed_model, device=device)\nprint(f\"âœ… Embedder loaded\")\n\n# Extract chunk texts\nid2doc = [chunk[\"chunk\"] for chunk in chunks]\nprint(f\"ðŸ“Š Encoding {len(id2doc)} chunks...\")\n\n# Create embeddings\nembeddings = embedder.encode(\n    id2doc,\n    normalize_embeddings=True,\n    show_progress_bar=True,\n    batch_size=64,\n    convert_to_numpy=True\n).astype('float32')\n\nprint(f\"âœ… Embeddings shape: {embeddings.shape}\")\n\n# Build FAISS index\ndim = embeddings.shape[1]\nindex = faiss.IndexFlatIP(dim)\nindex.add(embeddings)\n\nprint(f\"âœ… FAISS index built: {index.ntotal} vectors, dimension {dim}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:28:07.544810Z","iopub.execute_input":"2025-11-01T18:28:07.545191Z","iopub.status.idle":"2025-11-01T18:28:38.445901Z","shell.execute_reply.started":"2025-11-01T18:28:07.545170Z","shell.execute_reply":"2025-11-01T18:28:38.445193Z"}},"outputs":[{"name":"stdout","text":"ðŸ“¦ Loading embedder: sentence-transformers/all-MiniLM-L6-v2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c59f4143856049648bfbcf39bdf8fc32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35e35858d6584b8fa8374d098f8364cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5860d0053cd24c43b6eb18bc1df2da9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcdfcbf02357496cbbff42efea7b2afd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cb62cba2f13427c8a9aaaa83f4dfefc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d76f3f5dd2624b02bee763bd29bed755"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97227e1f08e74733982aa675487be07f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49600cf1f8b1423198f37699a5a8ddc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b53d1f3504648adac1f34561cdb10b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fbd2a5afe604fb4a9713742720be7ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"550e03994b2d4aeeb502f91104229f21"}},"metadata":{}},{"name":"stdout","text":"âœ… Embedder loaded\nðŸ“Š Encoding 22565 chunks...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/353 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c5ece6798744975803e8639a3a29346"}},"metadata":{}},{"name":"stdout","text":"âœ… Embeddings shape: (22565, 384)\nâœ… FAISS index built: 22565 vectors, dimension 384\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ===================== CELL 6: BUILD BM25 INDEX =====================\n\n# Tokenize for BM25\nprint(f\"ðŸ”¨ Building BM25 index...\")\nbm25_corpus = [word_tokenize(doc.lower()) for doc in id2doc]\nbm25 = BM25Okapi(bm25_corpus)\nprint(f\"âœ… BM25 index built\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:28:38.447801Z","iopub.execute_input":"2025-11-01T18:28:38.448150Z","iopub.status.idle":"2025-11-01T18:28:46.655751Z","shell.execute_reply.started":"2025-11-01T18:28:38.448118Z","shell.execute_reply":"2025-11-01T18:28:46.654881Z"}},"outputs":[{"name":"stdout","text":"ðŸ”¨ Building BM25 index...\nâœ… BM25 index built\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ===================== CELL 7: SAVE INDEXES =====================\n\n# File names\nindex_file = f\"{config.name}_faiss.index\"\nid2doc_file = f\"{config.name}_id2doc.pkl\"\nmetadata_file = f\"{config.name}_metadata.json\"\n\n# Save FAISS index\nprint(f\"ðŸ’¾ Saving FAISS index to {index_file}...\")\nfaiss.write_index(index, index_file)\n\n# Save id2doc mapping\nprint(f\"ðŸ’¾ Saving id2doc to {id2doc_file}...\")\nwith open(id2doc_file, \"wb\") as f:\n    pickle.dump(id2doc, f)\n\n# Save metadata\nmetadata = {\n    \"created_at\": time.time(),\n    \"domain\": config.name,\n    \"dataset\": config.dataset_name,\n    \"n_vectors\": int(index.ntotal),\n    \"embedding_dim\": dim,\n    \"chunk_window\": config.chunk_window,\n    \"chunk_stride\": config.chunk_stride,\n    \"embed_model\": config.embed_model\n}\n\nprint(f\"ðŸ’¾ Saving metadata to {metadata_file}...\")\nwith open(metadata_file, \"w\") as f:\n    json.dump(metadata, f, indent=2)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"âœ… INDEX BUILDING COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"ðŸ“ Files created:\")\nprint(f\"  - {index_file}\")\nprint(f\"  - {id2doc_file}\")\nprint(f\"  - {metadata_file}\")\nprint(f\"\\nðŸ“Š Statistics:\")\nprint(f\"  - Total vectors: {index.ntotal}\")\nprint(f\"  - Embedding dimension: {dim}\")\nprint(f\"  - Source Q&A pairs: {len(qa_data)}\")\nprint(f\"  - Chunks created: {len(chunks)}\")\nprint(\"=\"*80)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:28:46.656652Z","iopub.execute_input":"2025-11-01T18:28:46.657246Z","iopub.status.idle":"2025-11-01T18:28:46.709487Z","shell.execute_reply.started":"2025-11-01T18:28:46.657217Z","shell.execute_reply":"2025-11-01T18:28:46.708713Z"}},"outputs":[{"name":"stdout","text":"ðŸ’¾ Saving FAISS index to mental_health_faiss.index...\nðŸ’¾ Saving id2doc to mental_health_id2doc.pkl...\nðŸ’¾ Saving metadata to mental_health_metadata.json...\n\n================================================================================\nâœ… INDEX BUILDING COMPLETE!\n================================================================================\nðŸ“ Files created:\n  - mental_health_faiss.index\n  - mental_health_id2doc.pkl\n  - mental_health_metadata.json\n\nðŸ“Š Statistics:\n  - Total vectors: 22565\n  - Embedding dimension: 384\n  - Source Q&A pairs: 3512\n  - Chunks created: 22565\n================================================================================\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ===================== CELL 8: VERIFY INDEX (OPTIONAL) =====================\n\ndef test_retrieval(query: str, top_k: int = 5):\n    \"\"\"Test the built index with a sample query.\"\"\"\n    print(f\"\\nðŸ” Testing query: '{query}'\")\n    \n    # Embed query\n    query_emb = embedder.encode([query], normalize_embeddings=True, convert_to_numpy=True).astype('float32')\n    \n    # Search FAISS\n    D, I = index.search(query_emb, top_k)\n    \n    print(f\"\\nðŸ“‹ Top {top_k} results:\")\n    for i, (idx, score) in enumerate(zip(I[0], D[0]), 1):\n        print(f\"\\n{i}. Score: {score:.4f}\")\n        print(f\"   {id2doc[idx][:200]}...\")\n\n# Test queries\ntest_queries = [\n    \"I feel anxious and depressed\",\n    \"How to deal with stress?\",\n    \"I'm having panic attacks\"\n]\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ðŸ§ª TESTING INDEX\")\nprint(\"=\"*80)\n\nfor query in test_queries:\n    test_retrieval(query, top_k=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:28:46.710505Z","iopub.execute_input":"2025-11-01T18:28:46.710792Z","iopub.status.idle":"2025-11-01T18:28:46.793565Z","shell.execute_reply.started":"2025-11-01T18:28:46.710769Z","shell.execute_reply":"2025-11-01T18:28:46.792834Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nðŸ§ª TESTING INDEX\n================================================================================\n\nðŸ” Testing query: 'I feel anxious and depressed'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e306eb6e77540349e4638181f077ce5"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“‹ Top 3 results:\n\n1. Score: 0.6048\n   I am very sorry that you are struggling. I have a few thoughts and perhaps some of my colleagues will add something else. Depression and anxiety can both be chronic conditions, as you have experienced...\n\n2. Score: 0.6048\n   I am very sorry that you are struggling. I have a few thoughts and perhaps some of my colleagues will add something else. Depression and anxiety can both be chronic conditions, as you have experienced...\n\n3. Score: 0.5910\n   You are not alone, and many people are experiencing very similar\nanxieties. A Life Coach or professional therapist could help to guide you\nthrough these emotions and refer you to additional profession...\n\nðŸ” Testing query: 'How to deal with stress?'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3da8925e8d8f409086a1b68d9e357ecd"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“‹ Top 3 results:\n\n1. Score: 0.7620\n   So, instead you need to find ways to help live with the stressors that you already have. They can be things like creating a more manageable schedule, introducing healthy eating or exercising, financia...\n\n2. Score: 0.7604\n   Try to take care\nof yourself in other ways, such as eating well. Exercise can really help when\nwe get stressed. I hope some of this was helpful....\n\n3. Score: 0.7604\n   Try to take care\nof yourself in other ways, such as eating well. Exercise can really help when\nwe get stressed. I hope some of this was helpful....\n\nðŸ” Testing query: 'I'm having panic attacks'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f8b7fba4d964b7eb0fb3e6eac5995a9"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“‹ Top 3 results:\n\n1. Score: 0.6304\n   Remember that I'm not asking you to actually diagnose yourself with one of these things, but just offering some basic information that may help you be able to talk about what is going on.If you are ha...\n\n2. Score: 0.6304\n   Remember that I'm not asking you to actually diagnose yourself with one of these things, but just offering some basic information that may help you be able to talk about what is going on.If you are ha...\n\n3. Score: 0.6271\n   Anxiety or panic attacks can be very frightening. Here are a few \"tools\" you can use that will help in the short term: Â Keeping your mind occupied by listening to books on tape may help; Â Counting bac...\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}