{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================== CELL 1: DEPENDENCIES ==========================\nimport subprocess\nimport sys\n\nprint('ðŸ”§ Installing dependencies...')\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"pyarrow\"], capture_output=True, check=False)\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyarrow==15.0.2\", \"keybert\", \"rank-bm25\", \"faiss-cpu\", \"sacremoses\"], check=True)\nprint('âœ… Dependencies installed. RESTART kernel and run Cell 2.')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== CELL 2: IMPORTS & SETUP =====================\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport re\nimport json\nimport time\nimport pickle\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Tuple\n\nimport numpy as np\nimport torch\nimport faiss\nfrom datasets import load_dataset\nfrom sentence_transformers import SentenceTransformer\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom rank_bm25 import BM25Okapi\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"ðŸ”§ Using device: {device}\")\n\n# ============================================================================\n# CONFIGURATION FOR NUTRITION & LIFESTYLE DOMAIN\n# ============================================================================\n\n@dataclass\nclass DomainConfig:\n    name: str = \"nutrition\"\n    dataset_name: str = \"medalpaca/medical_meadow_health_advice\"\n    dataset_split: str = \"train\"\n    chunk_window: int = 3\n    chunk_stride: int = 1\n    embed_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n\nconfig = DomainConfig()\n\nprint(f\"ðŸ“‹ Building index for: {config.name}\")\nprint(f\"ðŸ“¦ Dataset: {config.dataset_name}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T14:06:05.014573Z","iopub.execute_input":"2025-11-03T14:06:05.014819Z","iopub.status.idle":"2025-11-03T14:06:34.016512Z","shell.execute_reply.started":"2025-11-03T14:06:05.014798Z","shell.execute_reply":"2025-11-03T14:06:34.015839Z"}},"outputs":[{"name":"stderr","text":"2025-11-03 14:06:19.646983: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762178779.862771     104 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762178779.925664     104 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ðŸ”§ Using device: cpu\nðŸ“‹ Building index for: nutrition\nðŸ“¦ Dataset: medalpaca/medical_meadow_health_advice\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ===================== CELL 3: DATASET LOADING =====================\n\ndef extract_qa_pairs(dataset) -> list:\n    \"\"\"Extract Q&A pairs from MedAlpaca health advice dataset.\"\"\"\n    qa_data = []\n    \n    for idx, row in enumerate(dataset):\n        try:\n            question = \"\"\n            answer = \"\"\n            \n            # MedAlpaca structure: 'instruction' and 'output'\n            if 'instruction' in row and 'output' in row:\n                question = str(row['instruction']).strip()\n                answer = str(row['output']).strip()\n            \n            # Alternative structure: 'input' and 'output'\n            elif 'input' in row and 'output' in row:\n                question = str(row['input']).strip()\n                answer = str(row['output']).strip()\n            \n            # Generic structure\n            elif 'question' in row and 'answer' in row:\n                question = str(row['question']).strip()\n                answer = str(row['answer']).strip()\n            \n            # Validate and add\n            if question and answer and len(answer) > 20:\n                qa_data.append({\n                    \"question\": question,\n                    \"answer\": answer,\n                    \"source_id\": idx\n                })\n                \n        except Exception as e:\n            if idx < 3:\n                print(f\"âš ï¸ Row {idx} skipped: {e}\")\n            continue\n    \n    return qa_data\n\n# Load dataset\nprint(f\"ðŸ“¥ Loading {config.dataset_name}...\")\ndataset = load_dataset(config.dataset_name, split=config.dataset_split)\nprint(f\"âœ… Loaded {len(dataset)} rows\")\n\n# Print sample row to verify structure\nprint(f\"\\nðŸ“‹ Sample row structure:\")\nprint(f\"Keys: {list(dataset[0].keys())}\")\n\n# Extract Q&A pairs\nprint(f\"\\nðŸ” Extracting nutrition & lifestyle Q&A pairs...\")\nqa_data = extract_qa_pairs(dataset)\nprint(f\"âœ… Extracted {len(qa_data)} Q&A pairs\")\n\nif len(qa_data) < 100:\n    print(f\"âš ï¸ WARNING: Only {len(qa_data)} pairs extracted!\")\nelse:\n    print(f\"\\nðŸ“ Sample nutrition Q&A:\")\n    if qa_data:\n        print(f\"Q: {qa_data[0]['question'][:150]}...\")\n        print(f\"A: {qa_data[0]['answer'][:150]}...\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T14:06:34.017591Z","iopub.execute_input":"2025-11-03T14:06:34.018109Z","iopub.status.idle":"2025-11-03T14:06:35.522087Z","shell.execute_reply.started":"2025-11-03T14:06:34.018092Z","shell.execute_reply":"2025-11-03T14:06:35.521087Z"}},"outputs":[{"name":"stdout","text":"ðŸ“¥ Loading medalpaca/medical_meadow_health_advice...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d82965cfee0d48d59f0a2ebbb2837203"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"medical_meadow_health_advice.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf680f859cc24fd1b697c3cb5cb0859a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/8676 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f9f593cec034cb796cd73341d8940b0"}},"metadata":{}},{"name":"stdout","text":"âœ… Loaded 8676 rows\n\nðŸ“‹ Sample row structure:\nKeys: ['output', 'instruction', 'input']\n\nðŸ” Extracting nutrition & lifestyle Q&A pairs...\nâœ… Extracted 2199 Q&A pairs\n\nðŸ“ Sample nutrition Q&A:\nQ: Question: is this a 2) strong advice, 1) weak advice 0) no advice?...\nA: This is a weak advice...\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def create_chunks(data: List[Dict], window: int = 3, stride: int = 1, min_chars: int = 10) -> List[Dict]:\n    \"\"\"Create sentence-level chunks from answers.\"\"\"\n    chunks = []\n    for item in data:\n        text = item.get(\"answer\", \"\")\n        if not text or len(text) < min_chars:  # Lower to 10 chars\n            continue\n\n        sentences = sent_tokenize(text)\n        if not sentences:\n            continue\n\n        if len(sentences) <= window:\n            chunks.append({\n                \"chunk\": \" \".join(sentences),\n                \"source_idx\": item.get(\"source_id\", -1),\n                \"chunk_id\": len(chunks)\n            })\n            continue\n\n        for i in range(0, max(1, len(sentences) - window + 1), stride):\n            chunks.append({\n                \"chunk\": \" \".join(sentences[i:i + window]),\n                \"source_idx\": item.get(\"source_id\", -1),\n                \"chunk_id\": len(chunks)\n            })\n    return chunks\n\nprint(f\"ðŸ”ª Creating chunks (window={config.chunk_window}, stride={config.chunk_stride}, min_chars=10)...\")\nchunks = create_chunks(qa_data, window=config.chunk_window, stride=config.chunk_stride, min_chars=10)\nprint(f\"âœ… Created {len(chunks)} chunks\")\n\nif len(chunks) == 0:\n    print(\"[âŒ ERROR] No chunks created! Review the extracted sample answers, min_chars, or dataset format.\")\nelse:\n    print(\"\\nðŸ“ Sample chunk:\")\n    for i, chunk in enumerate(chunks[:3]):\n        print(f\"{i+1}. {chunk['chunk'][:120]}...\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T14:09:27.800037Z","iopub.execute_input":"2025-11-03T14:09:27.801226Z","iopub.status.idle":"2025-11-03T14:09:27.842027Z","shell.execute_reply.started":"2025-11-03T14:09:27.801186Z","shell.execute_reply":"2025-11-03T14:09:27.841284Z"}},"outputs":[{"name":"stdout","text":"ðŸ”ª Creating chunks (window=3, stride=1, min_chars=10)...\nâœ… Created 2199 chunks\n\nðŸ“ Sample chunk:\n1. This is a weak advice...\n2. This is a strong advice...\n3. This is a weak advice...\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ===================== CELL 5: BUILD FAISS INDEX =====================\n\n# Load embedder\nprint(f\"ðŸ“¦ Loading embedder: {config.embed_model}\")\nembedder = SentenceTransformer(config.embed_model, device=device)\nprint(f\"âœ… Embedder loaded\")\n\n# Extract chunk texts\nid2doc = [chunk[\"chunk\"] for chunk in chunks]\nprint(f\"ðŸ“Š Encoding {len(id2doc)} chunks...\")\n\n# Create embeddings\nembeddings = embedder.encode(\n    id2doc,\n    normalize_embeddings=True,\n    show_progress_bar=True,\n    batch_size=64,\n    convert_to_numpy=True\n).astype('float32')\n\nprint(f\"âœ… Embeddings shape: {embeddings.shape}\")\n\n# Build FAISS index\ndim = embeddings.shape[1]\nindex = faiss.IndexFlatIP(dim)\nindex.add(embeddings)\n\nprint(f\"âœ… FAISS index built: {index.ntotal} vectors, dimension {dim}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T14:09:32.443674Z","iopub.execute_input":"2025-11-03T14:09:32.443986Z","iopub.status.idle":"2025-11-03T14:09:36.002321Z","shell.execute_reply.started":"2025-11-03T14:09:32.443969Z","shell.execute_reply":"2025-11-03T14:09:36.001365Z"}},"outputs":[{"name":"stdout","text":"ðŸ“¦ Loading embedder: sentence-transformers/all-MiniLM-L6-v2\nâœ… Embedder loaded\nðŸ“Š Encoding 2199 chunks...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38f1faa53d6e4052a834d55c20b6807d"}},"metadata":{}},{"name":"stdout","text":"âœ… Embeddings shape: (2199, 384)\nâœ… FAISS index built: 2199 vectors, dimension 384\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ===================== CELL 6: BUILD BM25 INDEX =====================\n\n# Tokenize for BM25\nprint(f\"ðŸ”¨ Building BM25 index...\")\nbm25_corpus = [word_tokenize(doc.lower()) for doc in id2doc]\nbm25 = BM25Okapi(bm25_corpus)\nprint(f\"âœ… BM25 index built\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T14:09:36.003347Z","iopub.execute_input":"2025-11-03T14:09:36.003842Z","iopub.status.idle":"2025-11-03T14:09:36.098637Z","shell.execute_reply.started":"2025-11-03T14:09:36.003823Z","shell.execute_reply":"2025-11-03T14:09:36.097287Z"}},"outputs":[{"name":"stdout","text":"ðŸ”¨ Building BM25 index...\nâœ… BM25 index built\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ===================== CELL 7: SAVE INDEXES =====================\n\n# File names\nindex_file = f\"{config.name}_faiss.index\"\nid2doc_file = f\"{config.name}_id2doc.pkl\"\nmetadata_file = f\"{config.name}_metadata.json\"\n\n# Save FAISS index\nprint(f\"ðŸ’¾ Saving FAISS index to {index_file}...\")\nfaiss.write_index(index, index_file)\n\n# Save id2doc mapping\nprint(f\"ðŸ’¾ Saving id2doc to {id2doc_file}...\")\nwith open(id2doc_file, \"wb\") as f:\n    pickle.dump(id2doc, f)\n\n# Save metadata\nmetadata = {\n    \"created_at\": time.time(),\n    \"domain\": config.name,\n    \"dataset\": config.dataset_name,\n    \"n_vectors\": int(index.ntotal),\n    \"embedding_dim\": dim,\n    \"chunk_window\": config.chunk_window,\n    \"chunk_stride\": config.chunk_stride,\n    \"embed_model\": config.embed_model\n}\n\nprint(f\"ðŸ’¾ Saving metadata to {metadata_file}...\")\nwith open(metadata_file, \"w\") as f:\n    json.dump(metadata, f, indent=2)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"âœ… INDEX BUILDING COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"ðŸ“ Files created:\")\nprint(f\"  - {index_file}\")\nprint(f\"  - {id2doc_file}\")\nprint(f\"  - {metadata_file}\")\nprint(f\"\\nðŸ“Š Statistics:\")\nprint(f\"  - Total vectors: {index.ntotal}\")\nprint(f\"  - Embedding dimension: {dim}\")\nprint(f\"  - Source Q&A pairs: {len(qa_data)}\")\nprint(f\"  - Chunks created: {len(chunks)}\")\nprint(\"=\"*80)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T14:09:36.099546Z","iopub.execute_input":"2025-11-03T14:09:36.099919Z","iopub.status.idle":"2025-11-03T14:09:36.126589Z","shell.execute_reply.started":"2025-11-03T14:09:36.099807Z","shell.execute_reply":"2025-11-03T14:09:36.125651Z"}},"outputs":[{"name":"stdout","text":"ðŸ’¾ Saving FAISS index to nutrition_faiss.index...\nðŸ’¾ Saving id2doc to nutrition_id2doc.pkl...\nðŸ’¾ Saving metadata to nutrition_metadata.json...\n\n================================================================================\nâœ… INDEX BUILDING COMPLETE!\n================================================================================\nðŸ“ Files created:\n  - nutrition_faiss.index\n  - nutrition_id2doc.pkl\n  - nutrition_metadata.json\n\nðŸ“Š Statistics:\n  - Total vectors: 2199\n  - Embedding dimension: 384\n  - Source Q&A pairs: 2199\n  - Chunks created: 2199\n================================================================================\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ===================== CELL 8: VERIFY INDEX (OPTIONAL) =====================\n\ndef test_retrieval(query: str, top_k: int = 5):\n    \"\"\"Test the built index with a sample query.\"\"\"\n    print(f\"\\nðŸ” Testing query: '{query}'\")\n    \n    # Embed query\n    query_emb = embedder.encode([query], normalize_embeddings=True, convert_to_numpy=True).astype('float32')\n    \n    # Search FAISS\n    D, I = index.search(query_emb, top_k)\n    \n    print(f\"\\nðŸ“‹ Top {top_k} results:\")\n    for i, (idx, score) in enumerate(zip(I[0], D[0]), 1):\n        print(f\"\\n{i}. Score: {score:.4f}\")\n        print(f\"   {id2doc[idx][:200]}...\")\n\n# Test queries\ntest_queries = [\n    \"What foods are good for heart health?\",\n    \"How much protein should I eat daily?\",\n    \"What are the benefits of a Mediterranean diet?\"\n]\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ðŸ§ª TESTING NUTRITION INDEX\")\nprint(\"=\"*80)\n\nfor query in test_queries:\n    test_retrieval(query, top_k=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T14:10:15.879192Z","iopub.execute_input":"2025-11-03T14:10:15.879464Z","iopub.status.idle":"2025-11-03T14:10:15.967422Z","shell.execute_reply.started":"2025-11-03T14:10:15.879446Z","shell.execute_reply":"2025-11-03T14:10:15.966659Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nðŸ§ª TESTING NUTRITION INDEX\n================================================================================\n\nðŸ” Testing query: 'What foods are good for heart health?'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f633c857ce4c47dbb0e12005857d882a"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“‹ Top 3 results:\n\n1. Score: 0.1188\n   This is a strong advice...\n\n2. Score: 0.1188\n   This is a strong advice...\n\n3. Score: 0.1188\n   This is a strong advice...\n\nðŸ” Testing query: 'How much protein should I eat daily?'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f8a5c7e6ba54bcea6ab4238129e1173"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“‹ Top 3 results:\n\n1. Score: 0.1184\n   This is a strong advice...\n\n2. Score: 0.1184\n   This is a strong advice...\n\n3. Score: 0.1184\n   This is a strong advice...\n\nðŸ” Testing query: 'What are the benefits of a Mediterranean diet?'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e5c1e97dd304443b243d98f814d7752"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“‹ Top 3 results:\n\n1. Score: 0.0980\n   This is a strong advice...\n\n2. Score: 0.0980\n   This is a strong advice...\n\n3. Score: 0.0980\n   This is a strong advice...\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}